{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10966520,"sourceType":"datasetVersion","datasetId":6823076}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import Ridge\nfrom statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\nfrom sklearn.metrics import mean_squared_log_error, mean_absolute_error, r2_score\n\n# âœ… Load Training Data\ntry:\n    store_sales = pd.read_csv(\n        \"/kaggle/input/store-sales-time-series-forecasting-2/train.csv\",\n        usecols=['store_nbr', 'family', 'date', 'sales'],\n        dtype={'store_nbr': 'category', 'family': 'category', 'sales': 'float32'},\n        parse_dates=['date'],\n    )\n    store_sales['date'] = store_sales.date.dt.to_period('D')\n    store_sales = store_sales.set_index(['store_nbr', 'family', 'date']).sort_index()\n    print(\"ðŸ“Œ Training Data Sample:\\n\", store_sales.head())\nexcept FileNotFoundError as e:\n    print(f\"Error loading train.csv: {e}\")\n\n# Prepare target (y) - unstack to have store-family combinations as columns\ny = store_sales['sales'].unstack(['store_nbr', 'family']).loc[\"2017\"]\n\n# Split into training (Jan 1 - Jul 31, 2017) and validation (Aug 1 - Aug 15, 2017)\ny_train = y.loc['2017-01-01':'2017-07-31']\ny_val = y.loc['2017-08-01':'2017-08-15']\n\n# Calculate average sales and multiple lags\navg_sales = store_sales['sales'].groupby('date').mean().loc[\"2016\":\"2017\"]\nlag_sales_1 = avg_sales.shift(1).loc[\"2017\"].rename('lag_sales_1')\nlag_sales_2 = avg_sales.shift(2).loc[\"2017\"].rename('lag_sales_2')\nlag_sales_7 = avg_sales.shift(7).loc[\"2017\"].rename('lag_sales_7')\n\n# âœ… Load Holiday Data\ntry:\n    holidays_events = pd.read_csv(\n        \"/kaggle/input/store-sales-time-series-forecasting-2/holidays_events.csv\",\n        dtype={'type': 'category', 'locale': 'category', 'locale_name': 'category', 'description': 'category', 'transferred': 'bool'},\n        parse_dates=['date'],\n    )\n    holidays_events['date'] = holidays_events.date.dt.to_period('D')\n    print(\"Loaded holidays_events.csv successfully\")\nexcept FileNotFoundError as e:\n    print(f\"Error loading holidays_events.csv: {e}\")\n\n# Filter national and regional holidays\nholidays = holidays_events.query(\"locale in ['National', 'Regional']\").loc['2017':'2017-08-31', ['description']]\nholidays = holidays.assign(description=lambda x: x.description.cat.remove_unused_categories())\n\n# âœ… Load Oil Data\ntry:\n    oil = pd.read_csv(\n        \"/kaggle/input/store-sales-time-series-forecasting-2/oil.csv\",\n        parse_dates=['date'],\n    ).set_index('date').to_period('D')\n    oil['dcoilwtico'] = oil['dcoilwtico'].ffill().bfill()\n    print(\"Loaded oil.csv successfully\")\nexcept FileNotFoundError as e:\n    print(f\"Error loading oil.csv: {e}\")\n\n# âœ… Prepare Training Features\nfourier = CalendarFourier(freq='ME', order=4)\ndp = DeterministicProcess(\n    index=y.index,\n    constant=True,\n    order=1,\n    seasonal=True,\n    additional_terms=[fourier],\n    drop=True,\n)\nX = dp.in_sample()\n\n# Split features into train and validation\nX_train = X.loc['2017-01-01':'2017-07-31']\nX_val = X.loc['2017-08-01':'2017-08-15']\n\n# Add New Year indicator\nX['NewYear'] = (X.index.dayofyear == 1)\n\n# Add holiday features\nX_holidays = pd.get_dummies(holidays, columns=['description'], dtype=float)\nX = X.join(X_holidays, on='date').fillna(0.0)\n\n# Add oil price feature\nX = X.join(oil['dcoilwtico'], on='date').ffill().bfill()\n\n# Add multiple lagged sales features\nX = X.join(lag_sales_1, on='date').join(lag_sales_2, on='date').join(lag_sales_7, on='date')\nX[['lag_sales_1', 'lag_sales_2', 'lag_sales_7']] = X[['lag_sales_1', 'lag_sales_2', 'lag_sales_7']].fillna(avg_sales.mean())\n\n# Verify no NaNs remain\nif X.isnull().any().any():\n    print(\"Warning: NaNs found in X after preprocessing:\")\n    print(X.isnull().sum())\n    raise ValueError(\"NaNs still present in training features\")\n\n# Split X again after adding features\nX_train = X.loc['2017-01-01':'2017-07-31']\nX_val = X.loc['2017-08-01':'2017-08-15']\n\nprint(\"ðŸ“Œ Final Training Features (X_train):\\n\", X_train.head())\n\n# âœ… Train Model\nmodel = Ridge(alpha=1.0)\nmodel.fit(X_train, y_train)\n\n# âœ… Evaluate on Validation Set\ny_val_pred = pd.DataFrame(model.predict(X_val), index=X_val.index, columns=y_val.columns)\n\n# Compute evaluation metrics\n# RMSLE (clip negative predictions to 0 as log can't handle negatives)\ny_val_true = y_val.stack(['store_nbr', 'family']).values\ny_val_pred_flat = y_val_pred.stack(['store_nbr', 'family']).values\ny_val_pred_flat = np.clip(y_val_pred_flat, 0, None)  # Avoid negative predictions\nrmsle = np.sqrt(mean_squared_log_error(y_val_true, y_val_pred_flat))\n\n# MAE\nmae = mean_absolute_error(y_val_true, y_val_pred_flat)\n\n# RÂ² Score\nr2 = r2_score(y_val_true, y_val_pred_flat)\n\nprint(\"\\nðŸ“Œ Validation Metrics:\")\nprint(f\"RMSLE: {rmsle:.4f}\")\nprint(f\"MAE: {mae:.4f}\")\nprint(f\"RÂ² Score: {r2:.4f}\")\n\n# Check in-sample predictions (on full training data for submission)\ny_pred = pd.DataFrame(model.predict(X), index=X.index, columns=y.columns)\nprint(\"ðŸ“Œ Sample Training Predictions (y_pred):\\n\", y_pred.head())\n\n# âœ… Load Test Data While Preserving 'id'\ntry:\n    df_test = pd.read_csv(\n        \"/kaggle/input/store-sales-time-series-forecasting-2/test.csv\",\n        dtype={'store_nbr': 'category', 'family': 'category'},\n        parse_dates=['date'],\n    )\n    df_test_id = df_test[['id', 'store_nbr', 'family', 'date']].copy()\n    df_test['date'] = df_test.date.dt.to_period('D')\n    df_test = df_test.set_index(['store_nbr', 'family', 'date']).sort_index()\n    print(\"Loaded test.csv successfully\")\nexcept FileNotFoundError as e:\n    print(f\"Error loading test.csv: {e}\")\n\n# âœ… Generate Test Features\ntest_dates = df_test.index.get_level_values('date').unique()\nX_test = dp.out_of_sample(steps=len(test_dates))\nX_test.index = test_dates\nX_test.index.name = 'date'\n\n# Add New Year indicator\nX_test['NewYear'] = (X_test.index.dayofyear == 1)\n\n# Add holiday features\nX_test = X_test.join(X_holidays, on='date').fillna(0.0)\n\n# Add oil price feature\nX_test = X_test.join(oil['dcoilwtico'], on='date').ffill().bfill()\n\n# Add lagged sales features for test period (using last available training values)\nlast_lag_1 = avg_sales.loc['2017-08-15']\nlast_lag_2 = avg_sales.loc['2017-08-14']\nlast_lag_7 = avg_sales.loc['2017-08-09']\nX_test['lag_sales_1'] = last_lag_1\nX_test['lag_sales_2'] = last_lag_2\nX_test['lag_sales_7'] = last_lag_7\n\n# Ensure feature consistency\nmissing_cols = set(X.columns) - set(X_test.columns)\nfor col in missing_cols:\n    X_test[col] = 0.0\nX_test = X_test[X.columns]\n\n# Verify no NaNs in test features\nif X_test.isnull().any().any():\n    print(\"Warning: NaNs found in X_test after preprocessing:\")\n    print(X_test.isnull().sum())\n    raise ValueError(\"NaNs still present in test features\")\n\nprint(\"ðŸ“Œ Final Test Features (X_test):\\n\", X_test.head())\n\n# âœ… Make Predictions\ny_submit = pd.DataFrame(model.predict(X_test), index=X_test.index, columns=y.columns)\ny_submit = y_submit.stack(['store_nbr', 'family'], future_stack=True).reset_index(name='sales')\n\n# âœ… Fix ID Loss Issue\ndf_test_id['date'] = df_test_id['date'].astype(str)\ny_submit['date'] = y_submit['date'].astype(str)\ny_submit = df_test_id.merge(y_submit, on=['store_nbr', 'family', 'date'], how='left')\ny_submit['sales'] = y_submit['sales'].fillna(0)\ny_submit = y_submit[['id', 'sales']]\n\n# âœ… Verify and Save Submission\nprint(\"\\nðŸ“Œ Sample of submission.csv with All Test IDs Preserved:\")\nprint(y_submit.head(10))\ny_submit.to_csv('/kaggle/working/submission.csv', index=False)\nprint(\"ðŸ“Œ Submission file generated successfully! ðŸ“Œ\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T03:31:48.065100Z","iopub.execute_input":"2025-03-10T03:31:48.065473Z","iopub.status.idle":"2025-03-10T03:32:07.822658Z","shell.execute_reply.started":"2025-03-10T03:31:48.065441Z","shell.execute_reply":"2025-03-10T03:32:07.821476Z"}},"outputs":[{"name":"stdout","text":"ðŸ“Œ Training Data Sample:\n                                  sales\nstore_nbr family     date             \n1         AUTOMOTIVE 2013-01-01    0.0\n                     2013-01-02    2.0\n                     2013-01-03    3.0\n                     2013-01-04    3.0\n                     2013-01-05    5.0\nLoaded holidays_events.csv successfully\nLoaded oil.csv successfully\nðŸ“Œ Final Training Features (X_train):\n             const  trend  s(2,7)  s(3,7)  s(4,7)  s(5,7)  s(6,7)  s(7,7)  \\\ndate                                                                       \n2017-01-01    1.0    1.0     0.0     0.0     0.0     0.0     0.0     0.0   \n2017-01-02    1.0    2.0     1.0     0.0     0.0     0.0     0.0     0.0   \n2017-01-03    1.0    3.0     0.0     1.0     0.0     0.0     0.0     0.0   \n2017-01-04    1.0    4.0     0.0     0.0     1.0     0.0     0.0     0.0   \n2017-01-05    1.0    5.0     0.0     0.0     0.0     1.0     0.0     0.0   \n\n            sin(1,freq=ME)  cos(1,freq=ME)  ...  cos(2,freq=ME)  \\\ndate                                        ...                   \n2017-01-01        0.000000        1.000000  ...        1.000000   \n2017-01-02        0.201299        0.979530  ...        0.918958   \n2017-01-03        0.394356        0.918958  ...        0.688967   \n2017-01-04        0.571268        0.820763  ...        0.347305   \n2017-01-05        0.724793        0.688967  ...       -0.050649   \n\n            sin(3,freq=ME)  cos(3,freq=ME)  sin(4,freq=ME)  cos(4,freq=ME)  \\\ndate                                                                         \n2017-01-01        0.000000        1.000000        0.000000        1.000000   \n2017-01-02        0.571268        0.820763        0.724793        0.688967   \n2017-01-03        0.937752        0.347305        0.998717       -0.050649   \n2017-01-04        0.968077       -0.250653        0.651372       -0.758758   \n2017-01-05        0.651372       -0.758758       -0.101168       -0.994869   \n\n            NewYear  dcoilwtico  lag_sales_1  lag_sales_2  lag_sales_7  \ndate                                                                    \n2017-01-01     True       53.75   622.341675   652.998291   699.684570  \n2017-01-02    False       53.75     6.780303   622.341675   579.557129  \n2017-01-03    False       52.36   786.928406     6.780303   472.769653  \n2017-01-04    False       53.26   619.740234   786.928406   533.969543  \n2017-01-05    False       53.77   555.607971   619.740234   501.744263  \n\n[5 rows x 21 columns]\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-1-29fb0710df78>:112: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n  y_val_true = y_val.stack(['store_nbr', 'family']).values\n<ipython-input-1-29fb0710df78>:113: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n  y_val_pred_flat = y_val_pred.stack(['store_nbr', 'family']).values\n","output_type":"stream"},{"name":"stdout","text":"\nðŸ“Œ Validation Metrics:\nRMSLE: 0.5549\nMAE: 84.4390\nRÂ² Score: 0.9472\nðŸ“Œ Sample Training Predictions (y_pred):\n store_nbr           1                                                          \\\nfamily     AUTOMOTIVE BABY CARE    BEAUTY    BEVERAGES     BOOKS BREAD/BAKERY   \ndate                                                                            \n2017-01-01   0.986276       0.0  1.499982   640.197814  0.270524   110.836785   \n2017-01-02   7.739112       0.0  2.254279  1693.741211  0.445458   315.805015   \n2017-01-03   3.898980       0.0  3.028823  2743.087406  1.285447   457.411317   \n2017-01-04   3.245901       0.0  4.519788  2759.927983  0.985035   503.967718   \n2017-01-05   3.623657       0.0  3.167645  2278.896405  0.702343   427.633712   \n\nstore_nbr                                                    ...         9  \\\nfamily     CELEBRATION     CLEANING       DAIRY        DELI  ... MAGAZINES   \ndate                                                         ...             \n2017-01-01    2.410941   186.931773  221.377792   39.178015  ...  2.391043   \n2017-01-02    8.718529   554.154705  579.198598  104.953165  ...  5.750576   \n2017-01-03   11.988400   747.147661  933.347588  185.792785  ...  2.357970   \n2017-01-04   16.546477  1006.103135  962.092847  152.111105  ...  1.271764   \n2017-01-05   17.515995   772.010200  773.415224  121.245192  ...  1.803366   \n\nstore_nbr                                                                  \\\nfamily           MEATS PERSONAL CARE PET SUPPLIES PLAYERS AND ELECTRONICS   \ndate                                                                        \n2017-01-01  239.583461    397.198113     5.712442               10.322810   \n2017-01-02  566.423284    934.796287     8.935715               28.031489   \n2017-01-03  621.203153    983.355046     9.534159               19.496886   \n2017-01-04  342.973912    513.814087     8.256728               11.387790   \n2017-01-05  542.595173    528.694977     5.760206               12.492139   \n\nstore_nbr                                                                      \\\nfamily         POULTRY PREPARED FOODS      PRODUCE SCHOOL AND OFFICE SUPPLIES   \ndate                                                                            \n2017-01-01  320.943324      84.424763  1123.355054                   3.421033   \n2017-01-02  705.657781     117.450870  2355.399184                  -0.654335   \n2017-01-03  755.275366     182.887513  3304.661574                   1.079995   \n2017-01-04  371.297992     107.122010  1314.506159                   2.958243   \n2017-01-05  387.546957     104.863402  1416.587727                   2.223209   \n\nstore_nbr              \nfamily        SEAFOOD  \ndate                   \n2017-01-01  10.024462  \n2017-01-02  23.925345  \n2017-01-03  26.090500  \n2017-01-04  10.438872  \n2017-01-05  11.890779  \n\n[5 rows x 1782 columns]\nLoaded test.csv successfully\nðŸ“Œ Final Test Features (X_test):\n             const  trend  s(2,7)  s(3,7)  s(4,7)  s(5,7)  s(6,7)  s(7,7)  \\\ndate                                                                       \n2017-08-16    1.0  228.0     0.0     0.0     1.0     0.0     0.0     0.0   \n2017-08-17    1.0  229.0     0.0     0.0     0.0     1.0     0.0     0.0   \n2017-08-18    1.0  230.0     0.0     0.0     0.0     0.0     1.0     0.0   \n2017-08-19    1.0  231.0     0.0     0.0     0.0     0.0     0.0     1.0   \n2017-08-20    1.0  232.0     0.0     0.0     0.0     0.0     0.0     0.0   \n\n            sin(1,freq=ME)  cos(1,freq=ME)  ...  cos(2,freq=ME)  \\\ndate                                        ...                   \n2017-08-16        0.101168       -0.994869  ...        0.979530   \n2017-08-17       -0.101168       -0.994869  ...        0.979530   \n2017-08-18       -0.299363       -0.954139  ...        0.820763   \n2017-08-19       -0.485302       -0.874347  ...        0.528964   \n2017-08-20       -0.651372       -0.758758  ...        0.151428   \n\n            sin(3,freq=ME)  cos(3,freq=ME)  sin(4,freq=ME)  cos(4,freq=ME)  \\\ndate                                                                         \n2017-08-16        0.299363       -0.954139       -0.394356        0.918958   \n2017-08-17       -0.299363       -0.954139        0.394356        0.918958   \n2017-08-18       -0.790776       -0.612106        0.937752        0.347305   \n2017-08-19       -0.998717       -0.050649        0.897805       -0.440394   \n2017-08-20       -0.848644        0.528964        0.299363       -0.954139   \n\n            NewYear  dcoilwtico  lag_sales_1  lag_sales_2  lag_sales_7  \ndate                                                                    \n2017-08-16    False       46.80   427.980896    427.00473   411.975128  \n2017-08-17    False       47.07   427.980896    427.00473   411.975128  \n2017-08-18    False       48.59   427.980896    427.00473   411.975128  \n2017-08-19    False       48.59   427.980896    427.00473   411.975128  \n2017-08-20    False       48.59   427.980896    427.00473   411.975128  \n\n[5 rows x 21 columns]\n\nðŸ“Œ Sample of submission.csv with All Test IDs Preserved:\n        id        sales\n0  3000888     4.274867\n1  3000889     0.000000\n2  3000890     3.134141\n3  3000891  2345.773238\n4  3000892     0.477652\n5  3000893   378.899936\n6  3000894    16.951001\n7  3000895   800.451537\n8  3000896   799.771159\n9  3000897   141.089784\nðŸ“Œ Submission file generated successfully! ðŸ“Œ\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}